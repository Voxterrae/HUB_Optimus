> Spanish version: [./es/05_meta_learning.md](./es/05_meta_learning.md)

# Meta-learning (EN)

The goal of meta-learning is to turn each simulation into concrete system improvements: scenario, rules, verification, metrics, and wording. It is not general reflection; it is learning engineering: detect failures, fix them, and test again.

---

## 1) Outcome in one sentence
- What was actually achieved (not what was intended)?

## 2) Signals and evidence
List 3-10 observable pieces of evidence:
- phrases/text where ambiguity appeared
- points where a party "escaped" due to lack of definition
- moments where verification was impossible
- key concessions that unlocked or blocked progress

## 3) Diagnosis (what failed and why)
Classify failures (mark all that apply):
- **Ambiguity:** undefined terms, fuzzy scope, vague deadlines.
- **Weak verification:** no actor, method, or sufficient access.
- **Misaligned incentives:** one party benefits from non-compliance.
- **Incorrect sequence:** step order makes the agreement unworkable.
- **Political overload:** internal cost makes acceptance impossible.
- **Spoilers:** external actors or events that break the agreement.
- **Information asymmetry:** one party negotiates blind.

## 4) Minimum viable patch (MVP)
Define the smallest change that improves the system:
- "If I could change only ONE thing, I would change: ____"
- How would the corrected text look (1-5 lines)?

## 5) Recommended changes (prioritized list)
Make a brief list (max 10), with priority:
1) **High:** breaks the simulation if not fixed
2) **Medium:** improves a lot, but does not block
3) **Low:** polish / style / minor improvements

For each change:
- what changes (file/section)
- why
- how to verify it improved (verifiable criterion)

## 6) Simple metrics (to compare iterations)
Choose 3-5 metrics and keep them over time:
- Clarity (0-5)
- Verifiability (0-5)
- Viability (0-5)
- Time to draft (min)
- Number of open points at close

## 7) Decision: repeat or scale?
- Repeat the same scenario with patches (iteration)
- Scale to a more complex variant (new scenario)
- Change the approach (another template/rule)

## 8) Record (strongly recommended)
Add to the end of the scenario or in notes:
- Date
- Participants/roles
- Outcome
- Changes applied
- Next experiment

---

## Closing checklist (30 seconds)
- [ ] Is there a final agreement text (even if partial)?
- [ ] Is it defined who verifies and how?
- [ ] Are deadlines and scope clear?
- [ ] Is there a list of open points?
- [ ] Is the minimum viable patch written down?

Next:
- Workflow (EN): [./README.md](./README.md)
- Template (EN): [./04_scenario_template.md](./04_scenario_template.md)