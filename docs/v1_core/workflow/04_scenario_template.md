> ðŸ‡ªðŸ‡¸ VersiÃ³n en espaÃ±ol: [./es/04_scenario_template.md](./es/04_scenario_template.md)

# Scenario Template

This template is designed to create comparable and easy-to-iterate scenarios. Keep sections consistent and be explicit: what is not defined becomes ambiguity during negotiation and evaluation.

This template follows the official [SCENARIO_SCHEMA](../../governance/SCENARIO_SCHEMA.md) structure to ensure comparability and auditability across all scenarios.

---

## 0) Scenario identification
- **Scenario ID:** `SCN-XXX` (e.g., SCN-004)
- **Domain:** `geopolitical` / `humanitarian` / `economic` / `environmental` / `other`
- **Version:** `v1.0` / `v0.x` (increment for significant changes)
- **Date / Last updated:** `YYYY-MM-DD`
- **Evaluator(s):** `name` or `HUB_Optimus (guided)`
- **Confidentiality level:** `public` / `internal` / `restricted`
- **Status:** `draft` / `stable` / `under review` / `archived`

---

## 1) Trigger
**What event, announcement, decision, or action activates this scenario analysis?**

Describe in 2â€“5 sentences:
- The specific event or decision point that initiates evaluation
- Why this event requires analysis (urgency, risk, impact)
- Observable signals or indicators that mark the trigger

**Example:** "Announcement of a partial ceasefire agreement between conflicting parties, without an independent verification mechanism or enforcement structure."

---

## 2) Structural context
**Baseline conditions that shape this scenario:**

- **Power asymmetries:** (who has structural advantage, dependencies)
- **External pressures:** (international, media, economic, political calendars)
- **Historical context:** (relevant precedents, patterns, prior attempts)
- **Time constraints:** (correction windows, urgency factors)
- **Resource availability:** (funding, personnel, infrastructure, access)

List 5â€“10 structural factors that define the operational environment.

---

## 3) Incentive analysis (Layer 2)
**Behavioral incentives and escalation risks:**

- **Rewarded behaviors:**
  - (what actions are incentivized by current structure?)
  - (short-term gains vs long-term stability)
  
- **Punished behaviors:**
  - (what constructive actions are disincentivized?)
  - (structural barriers to verification, transparency, compliance)

- **Escalation risks:**
  - (temptations to violate, plausible deniability opportunities)
  - (spoiler incentives, sabotage potential)

- **Signal analysis:**
  - Red flags: (observable indicators of structural failure)
  - Early warning signs: (predictable destabilization patterns)

**Output assessment:** Does the incentive structure favor stability or optics?

---

## 4) Human calibration (Layer 1)
**Cognitive and political biases affecting evaluation:**

- **Likely perception biases:**
  - (optimism bias, "peace achieved" framing)
  - (pressure to declare success)
  - (emotional relief reducing vigilance)

- **Political sensitivity:**
  - (who benefits from specific narratives?)
  - (reputational risks for different actors)

- **Urgency vs noise:**
  - (real timeline pressure vs manufactured urgency)
  - (signal-to-noise ratio in reporting)

- **Framing guidance:**
  - Recommended: neutral, evidence-based, non-celebratory
  - Avoid: premature declarations, optics-driven language

**Output:** Priority level (low / medium / high / critical) + framing recommendations

---

## 5) Systemic evaluation (Layer 3)
**Answer explicitly for each criterion (scale: negative / low / moderate / high / not applicable):**

1. **Future risk reduction:**
   - Does this scenario reduce likelihood of future escalation?
   - Assessment: _[your evaluation]_

2. **Medium/long-term stability:**
   - Does this create durable structures or temporary fixes?
   - Assessment: _[your evaluation]_

3. **Immediate suffering reduction:**
   - Does this provide meaningful relief to affected populations?
   - Assessment: _[your evaluation]_

4. **Incentive correction:**
   - Does this align incentives toward stability?
   - Assessment: _[your evaluation]_

5. **Lock-in / correction blockage:**
   - Does this enable future improvements or prevent them?
   - Assessment: _[your evaluation]_

**Outputs:**
- Risk classification: low / moderate / high / critical
- Stability impact: positive / neutral / negative
- Correctability window: open / closing / closed

---

## 6) Historical pattern check (Layer 5)
**Pattern matching with historical precedents:**

- **Pattern match:** yes / no / partial
  - Comparable cases: (list 2â€“5 similar scenarios from history)
  - Recurrent failure mode: (if pattern shows repeated failures, describe)
  
- **Learning from history:**
  - What went wrong in similar situations?
  - What interventions worked or failed?
  - What was missing that could have changed outcomes?

**Outputs:**
- Recurrence warning level: low / medium / high
- Recommended preventive actions based on historical lessons

---

## 7) Kernel coherence check (Layer 0)
**Alignment with HUB_Optimus supreme criterion (medium-long-term stability):**

- **Aligned with supreme criterion?** yes / no / partially
  - Justification: (explain alignment or drift)

- **Drift / Capture / Coercion check:**
  - Is there evidence of agenda capture?
  - Are external pressures distorting evaluation?
  - Does this represent optics over substance?

- **Decision:** approved / rejected / approved with conditions
  
**Rationale:**
(2â€“5 sentences explaining why this scenario passes or fails the Kernel coherence test)

**Example:** "Short-term relief does not justify long-term instability amplification. Violates supreme criterion."

---

## 8) Preventive mediation options (Layer 4)
**Non-coercive interventions to improve stability and verifiability:**

List 3â€“8 actionable options to improve the scenario:
- Reframe agreements (e.g., "provisional technical pause" instead of "ceasefire")
- Introduce minimal verification pilots
- Align incentives to reward compliance verification
- Delay public announcements until mechanisms exist
- Provide technical assistance for implementation
- Create independent monitoring structures
- Establish clear accountability frameworks
- Enable stakeholder participation

For each option, note:
- **Feasibility:** low / medium / high
- **Impact potential:** low / medium / high
- **Timeline:** immediate / short-term / medium-term

---

## 9) Action workflow steps (Final classification & recommended posture)
**Structured dialogue and verification process:**

### A) Negotiation rounds (recommended sequence)

- **Round 1 â€” Proposal & Response:**
  - **Action:** Initial proposal presentation â†” response with conditions
  - **Observable deliverables:** Draft text, preliminary commitments, counter-proposals
  - **Success criteria:** Partial acceptance + identified sticking points
  - **Timeline:** _[specify: hours / days / weeks]_

- **Round 2 â€” Technical Adjustments:**
  - **Action:** Refine verification mechanisms, sequencing, guarantees
  - **Observable deliverables:** Verification protocol, implementation timeline, resource commitments
  - **Success criteria:** Agreement on verification and enforcement mechanisms
  - **Timeline:** _[specify]_

- **Round 3 â€” Closure & Commitment:**
  - **Action:** Finalize agreement text + address open points
  - **Observable deliverables:** Signed agreement, implementation plan, accountability framework
  - **Success criteria:** Clear commitments with verification, next steps defined
  - **Timeline:** _[specify]_

### B) Verification workflow

- **Who verifies:** (organization / role / independent body)
- **What is verified:** (specific observable actions, events, compliance indicators)
- **How verification occurs:** (observation, reports, sensors, site access, third-party monitoring)
- **Verification frequency:** (continuous / daily / weekly / event-triggered)
- **Access requirements:** (zones, permissions, security arrangements)
- **Dispute resolution:** (process for conflicting reports or violations)

### C) Final deliverables

- **Draft agreement:** (8â€“15 lines summarizing commitments)
- **Open points list:** (unresolved issues requiring follow-up)
- **Next steps:** (specific actions, responsible parties, deadlines)
- **Success metrics:** (how will implementation be measured?)

### D) Outcome classification

- **Outcome type:** stabilizing / destabilizing (masked) / neutral / not evaluable
- **Primary risk vector:** (main failure mode if things go wrong)
- **Recommended posture:** 
  - engage publicly / engage discreetly / monitor / intervene structurally / reject

**Example classifications:**
- "Destabilizing (masked) â€” incentive misalignment â€” engage discreetly, intervene structurally"
- "Stabilizing â€” verified compliance framework â€” engage publicly, support implementation"

---

## 10) Memory integration
**Pattern reinforcement and learning storage:**

- **Pattern to strengthen or record:**
  - Name: (e.g., "Unverified Ceasefire Trap", "Successful Verification Pilot")
  - Category: failure mode / success pattern / neutral observation
  
- **Future trigger updates:**
  - What new early-warning indicators emerged?
  - What threshold adjustments are needed?
  
- **Knowledge to preserve:**
  - What worked unexpectedly well?
  - What assumed solutions failed?
  - What novel approaches emerged?

**Output:** Update pattern library and early-warning systems with findings.

---

## 11) Notes / GAPs / Meta-learning
**Reflective analysis for continuous improvement:**

- **What worked?**
  - Effective strategies, unexpected successes, valuable tools

- **What failed?**
  - Ineffective approaches, missed opportunities, analytical blind spots

- **What was missing?**
  - Information gaps, structural blind spots, resource constraints
  - What data would have improved evaluation?

- **What would you change next time?**
  - Process improvements, structure adjustments, focus areas

- **New questions that emerged:**
  - Unanswered questions requiring further research
  - Hypotheses for testing in future scenarios

- **Explicit GAPS:**
  - Mark clearly what information was unavailable
  - Note what prevented complete evaluation

**Next:** [./05_meta_learning.md](./05_meta_learning.md) for detailed guidance on iterative improvement.
